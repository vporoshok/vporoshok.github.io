---
title: Быстрая сортировка и рядом
description: Осколочные бомбы залетают на ходу, меня три раза обманули, я больше ничего не жду
date: 2020-02-29T06:57:38Z
draft: true
categories:
- algorithm
tags:
- stat
- random
- recursion
- complexity
toc: true
katex: true
mermaid: true
---

Ходит шутка, что быстрая сортировка потому называется быстрой, что её писать быстро:
```python
def quicksort(a):
    return a if len(a) <= 1 else (
        quicksort([x for x in a if x < a[0]]) +
        [x for x in a if x == a[0]] +
        quicksort([x for x in a if x > a[0]]))
```

Действительно, мало какой алгоритм сортировки может похвастаться такой лаконичностью, при этом внутри скрывается много деталей, которые мы постараемся раскрыть в этой статье.

## По порядку

Алгоритм быстрой сортировки является рекурсивным алгоритмом, основанным на делении входных данных. Подобным образом (правда куда более предсказуемым) работает алгоритм бинарного поиска в отсортированном массиве. Если описать алгоритм на естественном языке, то получится следующие 3 шага:
1. Выбрать опорный элемент \\(\\lambda\\).
2. Разбить входной массив \\(A\\) на 2 части:
{{<equation>}}
\{x \in A \colon x \leqslant \lambda\}
\quad \text{и} \quad
\{x \in A \colon x \geqslant \lambda\}.
{{</equation>}}
3. Повторить алгоритм для каждой части и «склеить» их вместе.

{{<note info>}}
Обратите внимание, что в обоих частях используются нестрогие неравенства, это не означает, что элементы равные \\(\\lambda\\) будут включены и туда, и туда, это позволяет лучше сбалансировать получающиеся части. Более подробно об этом будет рассказано в [части посвящённой разделению](#разбиение).
{{</note>}}

Каждый из этих шагов представляет из себя нетривиальную задачу, и будет разобран ниже. Однако, высокоуровнево алгоритм по сути строит бинарное дерево слияний, в котором листы состоят из одного элемента и упорядочены:
{{<mermaid>}}
graph TD
    A[2, 12, 85, 0, 6, 1, 17, 8]
    A -- "⩽ 12" --- B[2, 0, 6, 1, 8]
    B -- "⩽ 6" --- D[2, 0, 1]
    D -- "⩽ 1" --- H[0]
    D -- "⩾ 1" --- J[2, 1]
    J -- "⩽ 2" --- N[1]
    J -- "⩾ 2" --- O[2]
    B -- "⩾ 6" --- E[6, 8]
    E -- "⩽ 8" --- I[6]
    E -- "⩾ 8" --- K[8]
    A -- "⩾ 12" --- C[12, 85, 17]
    C -- "⩽ 17" --- F[12]
    C -- "⩾ 17" --- G[85, 17]
    G -- "⩽ 85" --- L[17]
    G -- "⩾ 85" --- M[85]
    P[0, 1, 2, 6, 8, 12, 17, 85]
    H --- P
    N --- P
    O --- P
    I --- P
    K --- P
    F --- P
    L --- P
    M --- P
{{</mermaid>}}

## Выбор опорного элемента

От выбора опорного элемента (англ. pivot) зависит насколько сбалансированным будет дерево разбиений, а от этого будет зависеть и сложность всей сортировки. Если опорная точка выбирается «плохо», то может получиться так, что массив будет разделён на часть, состоящую из одного элемента, и все оставшиеся. Если так будет происходить на каждой итерации, то получится дерево, глубины \\(N\\), а сложность всей сортировки будет \\(O(N^2)\\). Но как выбирать «хорошо»?

Ниже мы разберём эффективные способы нахождения «хорошего» опорного элемента за линейное время. Но они не применяются в реальной жизни из-за трудоёмкости. Обычно применяется случайный выбор опорного элемента. При этом случайность, используемая для выбора может быть либо внешней, либо внутренней.

Внешняя случайность подразумевает то, что случайность будет передана в программу снаружи. А именно то, что массив, поступающий на вход является случайным, то есть перестановка сортировки равномерно распределена в множестве всех возможных перестановок. Если это так, то в общем случае конкретный алгоритм выбора опорной точки не несёт принципиальной разницы: в качестве опорного элемента можно использовать первый, последний, средний, среднеарифметическое первого и последнего или любой другой детерминированный способ. Все перечисленные способы будут показывать хороший результат на случайных данных, но для каждого из них можно подобрать массив, на котором разбиение всегда будет «плохим»: для первого или последнего элемента --- отсортированный, для среднеарифметического первого и последнего --- массив вида \\([1, 3, 5, \\ldots, N, \\ldots, 6, 4, 2]\\) и так далее{{<qlink 1>}}.

Наиболее часто применяемый способ выбора опорного элемента с использованием внешней случайности является выбор медианы среди первого, среднего и последнего элементов входного массива:
```python
def lambda(a):
    x, y, z = 0, len(a) - 1, len(a) // 2
    if a[z] < a[x]:
        x, z = z, x
    if a[y] < a[x]:
        x, y = y, x
    if a[z] < a[y]:
        y, z = z, y
    return a[y]
```

Если же случайность входных данных не вызывает доверия, например, это пользовательский ввод с возможностью атаки, то следует применять внутреннюю случайность, другими словами использовать генератор случайных чисел. Пусть индекс опорного элемента является случайной величиной с равномерным распределением от \\(0\\) до \\(n - 1\\). Тогда, если математическое ожидание соотношения размеров частей после разбиения будет равна 1, таким образом математическое ожидание сложности всей сортировки будет \\(n\\log n \\).

## Разбиение

Это единственный этап, на котором производится перестановка элементов массива, поэтому от выбора алгоритма разбиения зависит будет ли весь алгоритм сортировки стабильным или нет.

{{<note info>}}
Сортировка называется _стабильной_, если не меняет порядок одинаковых элементов.

Другими словами, пусть необходимо отсортировать массив объектов, например, книг. При этом книги уже отсортированы по названию, но не отсортированы по автору:
1. Ремарк Э.-М. _На западном фронте без перемен_
1. Хемингуэй Э. _По ком звонит колокол_
1. Хемингуэй Э. _Праздник, который всегда с тобой_
1. Хемингуэй Э. _Прощай оружие_
1. Хемингуэй Э. _Старик и море_
1. Ремарк Э.-М. _Три товарища_

При стабильной сортировке мы всегда получим следующий результат:
1. Ремарк Э.-М. _На западном фронте без перемен_
1. Ремарк Э.-М. _Три товарища_
1. Хемингуэй Э. _По ком звонит колокол_
1. Хемингуэй Э. _Праздник, который всегда с тобой_
1. Хемингуэй Э. _Прощай оружие_
1. Хемингуэй Э. _Старик и море_

При нестабильной — порядок в группах по автору может измениться.
{{</note>}}

### Рзабиение Хоара

В данном разбиении создаются два указателя (первый и последний элемент не разбитой части), которые двигаются друг другу навстречу, совершая обмены по необходимости. Когда эти указатели встречаются, они указывают на позицию разбиения:
```python
def partition(a, p):
    i, j = 0, len(a)-1
    while True:
        while a[i] < p:
            i++
        while a[j] > p:
            j--
        if i >= j:
            return j
        a[i], a[j] = a[j], a[i]
        i++
        j--
```

Данный алгоритм можно хорошо оптимизировать, не обменивая элементы, равные `p`, или обменивая, если дисбаланс в скорости движения указателей. Небольшими доработками можно получить разбиение, которое разбивает массив одинаковых элементов на равные части без единого обмена. Однако, этот алгоритм невозможно сделать стабильным.

### Разбиенеи Ломуто

Другой способ разбиения предложил Нико Ломуто. Способ больше похож на сортировку вставками, разбитые части формируются от начала массива, и для каждого элемента массива определяется в какую часть он должен быть перенесён. Вводится также два указателя: элемент, по которому проходит разбиение и первый элемент, не включённый в разиение.
```python
def partition(a, p):
    i = 0
    for j in range(len(a)):
        if a[j] < p:
            a[i], a[j] = a[j], a[i]
            i++
    return i
```

То есть, с элементами большими или равными `p` не делается ничего, элементы же меньшие `p` перемещаются в конец первой части разбиения со сдвигом границы разбиения. Это перемещение несложно сделать стабильным. Также, перед разбиением можно посчитать сколько элементов массива меньше, больше и равно `p`, после чего вычислить сколько элементов, равных `p` необходимо включить в первую часть, за счёт чего сбалансировать размеры получаемых частей. Однако, разбиение Ломуто требует значительно больше обменов,

## Повторить об оптимизации хвостовой рекурсии

Наконец

## Оценка сложности
## Продвинутый выбор лямбды, порядковые статистики
## Рекурентные соотношения

## Вопросы

1. {{<qback 1>}} Опишите «плохие» массивы для методов выбора опорного элемента по среднему элементу массива и по медиане первого, среднего и последнего элементов.
